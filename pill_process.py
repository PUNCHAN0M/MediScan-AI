# pill_process.py
import os
import shutil
import random
import logging
import traceback
from pathlib import Path
from typing import Optional, List, Tuple
from config.base import SELECTED_CLASSES, SEED

# =============================================================================
# ‚öôÔ∏è CONFIGURATION
# =============================================================================

ROOT_INPUT_DIR = "data"
INPUT_MAINCLASS_DIR: Optional[str] = None  #['black_sphere']
INPUT_SUBCLASS_DIR: Optional[str] = None  #['black_sphere','brown_cap']

ROOT_BACKBONE_OUTPUT_DIR = "data_train_backbone"
ROOT_TRAIN_OUTPUT_DIR = "data_train_defection"

AUGMENT_COUNT_PER_IMAGE = 5
DEFECTION_MIN_IMAGES = 500
DEFECTION_MAX_IMAGES = 1000
BACKBONE_MIN_IMAGES = 500
BACKBONE_MAX_IMAGES = 1000
TRAIN_TEST_RATIO = 0.8  # 80% Train, 20% Test

# =============================================================================
# üõ†Ô∏è HELPER FUNCTIONS
# =============================================================================

def get_image_files(directory: Path) -> list[Path]:
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô directory"""
    if not directory.exists():
        return []
    extensions = ['*.png', '*.jpg', '*.jpeg', '*.bmp', '*.webp']
    files = []
    for ext in extensions:
        files.extend(directory.glob(ext))
    return files

def get_class_structure(
    root_dir: Path,
    main_filter: Optional[List[str] | str] = None,
    sub_filter: Optional[List[str] | str] = None
) -> List[Tuple[str, str]]:

    classes = []

    if not root_dir.exists():
        print(f"‚ùå Input directory not found: {root_dir}")
        return classes

    # üëâ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô list ‡πÄ‡∏™‡∏°‡∏≠
    if isinstance(main_filter, str):
        main_filter = [main_filter]
    if isinstance(sub_filter, str):
        sub_filter = [sub_filter]

    main_classes = [d.name for d in root_dir.iterdir() if d.is_dir()]

    # ================= MAIN CLASS FILTER =================
    if main_filter:
        main_classes = [m for m in main_classes if m in main_filter]

        if not main_classes:
            print(f"‚ö†Ô∏è Main class not found. Available: {[d.name for d in root_dir.iterdir() if d.is_dir()]}")
            return classes

    # ================= LOOP =================
    for main_cls in sorted(main_classes):
        main_path = root_dir / main_cls
        sub_classes = [d.name for d in main_path.iterdir() if d.is_dir()]

        if sub_filter:
            filtered_sub = [s for s in sub_classes if s in sub_filter]

            if not filtered_sub:
                print(f"‚ö†Ô∏è Sub class not found in '{main_cls}', available: {sub_classes}")
                continue

            sub_classes = filtered_sub

        for sub_cls in sorted(sub_classes):
            classes.append((main_cls, sub_cls))
            print(f"üìÅ Found class: {main_cls}/{sub_cls}")

    return classes

def ensure_dir(path: Path):
    path.mkdir(parents=True, exist_ok=True)

def limit_images(images: list[Path], min_count: int, max_count: int, label: str) -> list[Path]:
    """‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏° min/max config"""
    original_count = len(images)
    
    if original_count < min_count and images:
        print(f"‚ö†Ô∏è [{label}] Images ({original_count}) < min ({min_count}), duplicating...")
        needed = min_count - original_count
        extra = random.choices(images, k=needed)
        images = images + extra
        print(f"   ‚Üí After duplication: {len(images)} images")
    elif original_count < min_count:
        print(f"‚ö†Ô∏è [{label}] No images to duplicate, skipping min requirement")
    
    if len(images) > max_count:
        print(f"‚ö†Ô∏è [{label}] Images ({len(images)}) > max ({max_count}), sampling down...")
        images = random.sample(images, max_count)
        print(f"   ‚Üí After sampling: {len(images)} images")
    
    return images

def split_and_organize(images: list[Path], output_base: Path, label: str):
    """‡πÅ‡∏ö‡πà‡∏á Train/Test ‡∏à‡∏≤‡∏Å list ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ (‡πÑ‡∏°‡πà‡∏ó‡∏≥ limit ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ó‡∏≥‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÅ‡∏•‡πâ‡∏ß)"""
    ensure_dir(output_base / "train" / "good")
    ensure_dir(output_base / "test" / "good")
    
    random.shuffle(images)
    split_idx = int(len(images) * TRAIN_TEST_RATIO)
    
    train_images = images[:split_idx]
    test_images = images[split_idx:]
    
    for img in train_images:
        shutil.copy2(img, output_base / "train" / "good" / img.name)
    for img in test_images:
        shutil.copy2(img, output_base / "test" / "good" / img.name)
    
    print(f"‚úÖ [{label}] Train: {len(train_images)}, Test: {len(test_images)} | Total: {len(images)}")

# =============================================================================
# üîÑ AUGMENTATION (Updated for Minimal Output)
# =============================================================================

def run_augmentation(input_dir: Path, output_dir: Path, augment_count: int) -> list[Path]:
    """
    ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ pill_augment.py ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ list ‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å output_dir
    (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î Minimal ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ subfolder)
    """
    from pill_augment import PillAugmenter, CONFIG as AUG_CONFIG
    
    aug_config = AUG_CONFIG.copy()
    aug_config["INPUT_DIR"] = str(input_dir)
    aug_config["OUTPUT_DIR"] = str(output_dir)
    aug_config["AUGMENT_COUNT"] = augment_count
    aug_config["COMBINED_ONLY"] = True  # ‚úÖ ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÇ‡∏´‡∏°‡∏î Minimal
    
    augmenter = PillAugmenter(aug_config)
    augmenter.process_dataset()
    
    # ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å output_dir ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÑ‡∏°‡πà‡∏°‡∏µ subfolder 'combined')
    if output_dir.exists():
        augmented_images = get_image_files(output_dir)
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå augmented (‡∏ï‡∏±‡∏î original ‡∏≠‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£)
        # ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡πÉ‡∏´‡πâ limit_images ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠
    else:
        augmented_images = []
        logging.warning(f"‚ö†Ô∏è Output folder not found: {output_dir}")
    
    return augmented_images

def copy_to_backbone(images: list[Path], target_dir: Path, min_count: int, max_count: int):
    """‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏†‡∏≤‡∏û‡πÑ‡∏õ‡∏¢‡∏±‡∏á backbone directory ‡∏ï‡∏≤‡∏° min/max constraints"""
    ensure_dir(target_dir)
    
    if not images:
        print(f"‚ö†Ô∏è [backbone] No images to copy")
        return
    
    selected = limit_images(images, min_count, max_count, "backbone")
    
    for idx, img in enumerate(selected):
        new_name = f"aug_{idx:04d}_{img.name}"
        shutil.copy2(img, target_dir / new_name)
    
    print(f"üîß Backbone: Copied {len(selected)} images to {target_dir}")

# =============================================================================
# üöÄ PROCESS SINGLE CLASS (Fixed Split Logic)
# =============================================================================

def process_class(main_cls: str, sub_cls: str):
    print(f"\n{'='*60}")
    print(f"üî∑ Processing: {main_cls}/{sub_cls}")
    print(f"{'='*60}")

    input_dir = Path(ROOT_INPUT_DIR) / main_cls / sub_cls
    output_train_dir = Path(ROOT_TRAIN_OUTPUT_DIR) / main_cls / sub_cls
    output_backbone_dir = Path(ROOT_BACKBONE_OUTPUT_DIR) / f"{main_cls}_{sub_cls}"

    ensure_dir(output_train_dir / "train" / "good")
    ensure_dir(output_train_dir / "test" / "good")
    ensure_dir(output_backbone_dir)

    original_images = get_image_files(input_dir)
    print(f"üì∏ Found {len(original_images)} original images")

    if not original_images:
        print("‚ö†Ô∏è No images found, skipping...")
        return

    # ==========================================================
    # üî• STEP 1: AUGMENT ‚Üí ‡πÑ‡∏î‡πâ‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    # ==========================================================
    aug_output_dir = output_train_dir / "aug_all"
    ensure_dir(aug_output_dir)

    print("üé® Running augmentation...")
    all_augmented = run_augmentation(
        input_dir=input_dir,
        output_dir=aug_output_dir,
        augment_count=AUGMENT_COUNT_PER_IMAGE
    )

    print(f"üì¶ Total augmented images: {len(all_augmented)}")

    # limit ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö defection
    all_augmented = limit_images(
        all_augmented,
        DEFECTION_MIN_IMAGES,
        DEFECTION_MAX_IMAGES,
        "Defection All"
    )

    random.shuffle(all_augmented)

    # ==========================================================
    # üî• STEP 2: SPLIT ‚Üí 800 / 200
    # ==========================================================
    split_idx = int(len(all_augmented) * TRAIN_TEST_RATIO)

    train_imgs = all_augmented[:split_idx]
    test_imgs = all_augmented[split_idx:]

    for img in train_imgs:
        shutil.copy2(img, output_train_dir / "train" / "good" / img.name)

    for img in test_imgs:
        shutil.copy2(img, output_train_dir / "test" / "good" / img.name)

    print(f"‚úÖ Train: {len(train_imgs)} | Test: {len(test_imgs)}")

    # ==========================================================
    # üî• STEP 3: BACKBONE ‚Üí ‡∏™‡∏∏‡πà‡∏°‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å ALL (‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ)
    # ==========================================================
    copy_to_backbone(
        all_augmented,
        output_backbone_dir,
        BACKBONE_MIN_IMAGES,
        BACKBONE_MAX_IMAGES
    )

    # ==========================================================
    # üßπ CLEANUP
    # ==========================================================
    shutil.rmtree(aug_output_dir)

    print(f"‚úÖ Completed: {main_cls}/{sub_cls}")

# =============================================================================
# üöÄ MAIN ENTRY POINT
# =============================================================================

def main():
    print(f"üî∑ Pill Processing Pipeline Starting...")
    print(f"üìÇ Root Input: {ROOT_INPUT_DIR}")
    print(f"üéØ Main Class Filter: {INPUT_MAINCLASS_DIR or 'ALL'}")
    print(f"üéØ Sub Class Filter: {INPUT_SUBCLASS_DIR or 'ALL'}")
    
    class_list = get_class_structure(
        Path(ROOT_INPUT_DIR), 
        main_filter=INPUT_MAINCLASS_DIR, 
        sub_filter=INPUT_SUBCLASS_DIR
    )
    
    if not class_list:
        print("‚ùå No classes found to process. Please check your data structure.")
        return
    
    print(f"\nüìã Total classes to process: {len(class_list)}")
    
    for main_cls, sub_cls in class_list:
        try:
            process_class(main_cls, sub_cls)
        except Exception as e:
            print(f"üí• Error processing {main_cls}/{sub_cls}: {e}")
            traceback.print_exc()
            continue
    
    print(f"\n{'='*60}")
    print(f"üéâ Pipeline Complete!")
    print(f"{'='*60}")

if __name__ == "__main__":
    random.seed(SEED)
    main()