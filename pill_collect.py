#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pill Detection & Cropping System (Production Ready)
Support: YOLOv11 Segmentation (.pt / .onnx), Real-time / Batch mode, Grid Display
"""

import cv2
import os
import sys
import numpy as np
import torch
import logging
from pathlib import Path
from datetime import datetime
from ultralytics import YOLO

# =============================================================================
# ‚öôÔ∏è CONFIGURATION (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà)
# =============================================================================
CONFIG = {
    # Model Path (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö .pt ‡∏´‡∏£‡∏∑‡∏≠ .onnx)
    "MODEL_PATH": "model/SEGMENTATION/pill-detection-best-2.onnx",
    
    # Input: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠ "" ‡∏à‡∏∞‡πÉ‡∏ä‡πâ Real-time (Webcam), ‡∏ñ‡πâ‡∏≤‡πÉ‡∏™‡πà Path ‡∏à‡∏∞‡πÉ‡∏ä‡πâ Batch Mode
    "INPUT_DIR": None,  # Example: "data_yolo/dataset/" ‡∏´‡∏£‡∏∑‡∏≠ None
    
    # Output Directory ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà Crop ‡πÅ‡∏•‡πâ‡∏ß
    "OUTPUT_DIR": "data/red_cap/red_cap",
    
    # Confidence Threshold (0.0 - 1.0)
    "CONFIDENCE": 0.25,
    
    # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (256x256)
    "FINAL_SIZE": 256,
    
    # Real-time Settings
    "WEBCAM_ID": 0,           # ID ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á (0 = ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å)
    "GRID_MAX_COLS": 5,       # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡∏°‡πà
    "DISPLAY_SCALE": 1.0,     # Scale ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (‡∏õ‡∏£‡∏±‡∏ö‡∏ñ‡πâ‡∏≤‡∏à‡∏≠‡πÄ‡∏•‡πá‡∏Å/‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô)
    
    # Inference Settings
    "IMG_SIZE": 1280,         # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏¢‡∏¥‡πà‡∏á‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡∏ä‡πâ‡∏≤‡πÅ‡∏ï‡πà‡πÅ‡∏°‡πà‡∏ô)
    "RETINA_MASKS": True,     # ‡πÉ‡∏ä‡πâ High-res masks
    "USE_CUDA": True,         # ‡πÉ‡∏ä‡πâ GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
}

# =============================================================================
# üõ†Ô∏è SETUP & UTILITIES
# =============================================================================

# Setup Logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-8s | %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger(__name__)


class PillProcessor:
    """Class ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Detection, Cropping ‡πÅ‡∏•‡∏∞ Post-processing"""
    
    def __init__(self, config: dict):
        self.cfg = config
        self.output_dir = Path(config["OUTPUT_DIR"])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Setup Device
        self.device = 'cuda' if (config["USE_CUDA"] and torch.cuda.is_available()) else 'cpu'
        self.is_onnx = False  # Flag ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
        logger.info(f"üîß Using device: {self.device.upper()}")
        
        # Load Model
        self._load_model()
        
        # Counters for naming saved files
        self.save_counter = 0
        
    def _load_model(self):
        """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå (.pt vs .onnx)"""
        model_path = Path(self.cfg["MODEL_PATH"])
        if not model_path.exists():
            raise FileNotFoundError(f"‚ùå Model not found: {model_path}")
        
        logger.info(f"üì¶ Loading model: {model_path.name}")
        
        try:
            # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ‡πÇ‡∏´‡∏•‡∏î
            if model_path.suffix.lower() == '.onnx':
                self.is_onnx = True
                # ONNX: ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ task='segment' ‡πÅ‡∏•‡∏∞‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ .to()
                self.model = YOLO(str(model_path), task='segment')
                logger.info(f"‚úÖ ONNX Model loaded (Task: Segmentation)")
            else:
                self.is_onnx = False
                # PyTorch (.pt): ‡πÉ‡∏ä‡πâ .to() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ GPU ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥
                self.model = YOLO(str(model_path)).to(self.device)
                logger.info(f"‚úÖ PyTorch Model loaded | Format: {model_path.suffix}")
                
        except Exception as e:
            logger.error(f"‚ùå Failed to load model: {e}")
            raise
            
    def _preprocess_mask(self, mask: np.ndarray) -> np.ndarray:
        """‡∏ó‡∏≥ Post-processing ‡πÉ‡∏´‡πâ Mask ‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏∞‡∏≠‡∏≤‡∏î"""
        kernel = np.ones((5, 5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.GaussianBlur(mask, (7, 7), 0)
        _, mask = cv2.threshold(mask, 128, 255, cv2.THRESH_BINARY)
        return mask
    
    def _crop_and_square(self, image: np.ndarray, mask: np.ndarray) -> np.ndarray | None:
        """Crop ‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏° Mask ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ Square Padding ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≥ (‡πÑ‡∏°‡πà‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™)"""
        coords = cv2.findNonZero(mask)
        if coords is None:
            return None
        x, y, w, h = cv2.boundingRect(coords)
        
        # Crop ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞ mask
        crop_img = image[y:y+h, x:x+w].copy()
        crop_mask = mask[y:y+h, x:x+w].copy()
        
        # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏î‡∏≥ (BGR 3-channel) ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ BGRA ‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™
        max_dim = max(crop_img.shape[0], crop_img.shape[1])
        square_img = np.zeros((max_dim, max_dim, 3), dtype=np.uint8)  # ‚úÖ ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≥ [0,0,0]
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ß‡∏≤‡∏á‡∏†‡∏≤‡∏û crop ‡∏•‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≥
        pad_top = (max_dim - crop_img.shape[0]) // 2
        pad_left = (max_dim - crop_img.shape[1]) // 2
        
        # ‚úÖ ‡∏ß‡∏≤‡∏á‡∏†‡∏≤‡∏û crop ‡∏•‡∏á‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≥ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ mask ‡πÄ‡∏õ‡πá‡∏ô alpha blending
        # ‡πÅ‡∏õ‡∏•‡∏á mask ‡πÄ‡∏õ‡πá‡∏ô float [0,1] ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö blending
        alpha = crop_mask.astype(np.float32) / 255.0
        
        # ‡∏ß‡∏≤‡∏á‡∏ó‡∏µ‡∏•‡∏∞ channel (BGR)
        for c in range(3):
            # ‡∏™‡∏π‡∏ï‡∏£: result = pill * alpha + black * (1-alpha) ‚Üí black=0 ‡∏à‡∏∂‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÅ‡∏Ñ‡πà pill * alpha
            square_img[
                pad_top:pad_top+crop_img.shape[0], 
                pad_left:pad_left+crop_img.shape[1], 
                c
            ] = (crop_img[:, :, c] * alpha).astype(np.uint8)
        
        # ‚úÖ Resize ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏ô‡∏≤‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (256x256)
        final_img = cv2.resize(
            square_img, 
            (self.cfg["FINAL_SIZE"], self.cfg["FINAL_SIZE"]), 
            interpolation=cv2.INTER_LANCZOS4
        )
        
        return final_img  # ‚úÖ ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ BGR 3-channel (‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≥)
    
    def process_frame(self, frame: np.ndarray) -> tuple[list[np.ndarray], np.ndarray]:
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÄ‡∏ü‡∏£‡∏°"""
        cropped_pills = []
        display_frame = frame.copy()
        
        # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏™‡πà‡∏á device ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô predict() ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á .pt ‡πÅ‡∏•‡∏∞ .onnx)
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô ONNX Ultralytics ‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Device ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡∏°‡∏≤
        infer_device = None if self.is_onnx else self.device
            
        results = self.model.predict(
            source=frame,
            conf=self.cfg["CONFIDENCE"],
            save=False,
            retina_masks=self.cfg["RETINA_MASKS"],
            imgsz=self.cfg["IMG_SIZE"],
            device=infer_device,  # ‚úÖ ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ONNX ‡∏´‡πâ‡∏≤‡∏°‡∏™‡πà‡∏á device ‡∏ú‡πà‡∏≤‡∏ô .to() ‡πÅ‡∏ï‡πà‡∏™‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÑ‡∏î‡πâ
            verbose=False,
            task='segment' if self.is_onnx else None # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö task ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö onnx
        )
        
        if results[0].masks is None:
            return [], display_frame
            
        h_orig, w_orig = frame.shape[:2]
        masks_tensor = results[0].masks.data  # (N, H, W)
        
        for j in range(masks_tensor.shape[0]):
            # Resize mask ‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏†‡∏≤‡∏û‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
            m = masks_tensor[j].unsqueeze(0).unsqueeze(0)
            # ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ CPU ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢ OpenCV (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á 2 ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö)
            m = torch.nn.functional.interpolate(
                m, size=(h_orig, w_orig), mode='bilinear', align_corners=False
            )
            mask = (m.squeeze().cpu().numpy() * 255).astype(np.uint8)
            
            # Preprocess mask
            mask = self._preprocess_mask(mask)
            
            # Crop & Square
            cropped = self._crop_and_square(frame, mask)
            if cropped is not None:
                cropped_pills.append(cropped)
                
            # Draw bounding box
            coords = cv2.findNonZero(mask)
            if coords is not None:
                x, y, w, h = cv2.boundingRect(coords)
                cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                
        return cropped_pills, display_frame
    
    def save_pill(self, pill_img: np.ndarray, source_name: str = "realtime") -> str:
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û Pill ‡∏ó‡∏µ‡πà Crop ‡πÅ‡∏•‡πâ‡∏ß"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{source_name}_pill_{self.save_counter:04d}_{timestamp}.png"
        save_path = self.output_dir / filename
        cv2.imwrite(str(save_path), pill_img)
        self.save_counter += 1
        logger.info(f"üíæ Saved: {filename}")
        return str(save_path)


# ‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô create_grid_display
def create_grid_display(pills: list[np.ndarray], max_cols: int) -> np.ndarray | None:
    if not pills:
        return None
        
    size = pills[0].shape[0]
    n = len(pills)
    cols = min(n, max_cols)
    rows = (n + max_cols - 1) // max_cols
    
    # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏î‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á Grid (0 = ‡∏î‡∏≥)
    # ‡πÉ‡∏ä‡πâ 3 channels (BGR) ‡∏û‡∏≠‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≥‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Alpha
    grid = np.zeros((rows * size, cols * size, 3), dtype=np.uint8) 
    
    for idx, pill in enumerate(pills):
        row = idx // max_cols
        col = idx % max_cols
        y = row * size
        x = col * size
        
        # ‚úÖ ‡∏ß‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏•‡∏á Grid ‡πÇ‡∏î‡∏¢‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Alpha Blending ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏î‡∏≥
        if pill.shape[2] == 4:  # ‡∏°‡∏µ Alpha channel
            alpha = pill[:, :, 3:] / 255.0
            # ‡∏™‡∏π‡∏ï‡∏£: Final = Pill * Alpha + Black * (1-Alpha) -> Black ‡∏Ñ‡∏∑‡∏≠ 0 ‡∏à‡∏∂‡∏á‡∏ï‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏î‡πâ
            for c in range(3):  # BGR channels
                grid[y:y+size, x:x+size, c] = (pill[:, :, c] * alpha.squeeze()).astype(np.uint8)
        else:
            grid[y:y+size, x:x+size, :3] = pill
            
    return grid

def digital_zoom(frame, zoom=1.5):
    if zoom <= 1:
        return frame

    h, w = frame.shape[:2]

    new_w = int(w / zoom)
    new_h = int(h / zoom)

    x1 = (w - new_w) // 2
    y1 = (h - new_h) // 2

    cropped = frame[y1:y1+new_h, x1:x1+new_w]
    return cv2.resize(cropped, (w, h), interpolation=cv2.INTER_LINEAR)

def run_realtime(processor: PillProcessor, config: dict):
    """‡πÇ‡∏´‡∏°‡∏î Real-time: ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•"""
    cap = cv2.VideoCapture(config["WEBCAM_ID"])
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    if not cap.isOpened():
        logger.error(f"‚ùå Cannot open webcam ID {config['WEBCAM_ID']}")
        return
        
    logger.info("üé¨ Real-time mode started | Press 's' to save | 'q' to quit")
    
    while True:
        ret, frame = cap.read()
        frame = digital_zoom(frame, zoom=1.5)
        if not ret:
            logger.warning("‚ö†Ô∏è Failed to grab frame")
            break
            
        # Process
        pills, display_frame = processor.process_frame(frame)
        
        # Create Grid Display
        if pills:
            grid = create_grid_display(pills, config["GRID_MAX_COLS"])
            if grid is not None:
                # Convert BGRA -> BGR ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏î‡πâ‡∏ß‡∏¢ OpenCV
                grid_bgr = cv2.cvtColor(grid, cv2.COLOR_BGRA2BGR)
                
                # ‡πÅ‡∏™‡∏î‡∏á Grid ‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏´‡∏•‡∏±‡∏Å
                # Resize grid ‡πÉ‡∏´‡πâ‡∏™‡∏π‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡πÄ‡∏ü‡∏£‡∏°‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏ß‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢
                h_frame = display_frame.shape[0]
                grid_resized = cv2.resize(grid_bgr, (h_frame, h_frame))
                
                # ‡∏ß‡∏≤‡∏á Grid ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤‡∏Ç‡∏≠‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏´‡∏•‡∏±‡∏Å
                combined = np.hstack([display_frame, grid_resized])
            else:
                combined = display_frame
        else:
            combined = display_frame
            
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
        cv2.putText(
            combined, 
            f"Pills: {len(pills)} | Press 'S' to save | 'Q' to quit",
            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2
        )
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        scale = config["DISPLAY_SCALE"]
        if scale != 1.0:
            combined = cv2.resize(combined, (0, 0), fx=scale, fy=scale)
            
        cv2.imshow("Pill Detection System", combined)
        
        # Handle Key Press
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            logger.info("üëã Quitting...")
            break
        elif key == ord('s') and pills:
            logger.info(f"üíæ Saving {len(pills)} pill(s)...")
            for pill in pills:
                processor.save_pill(pill, source_name="realtime")
                
    # Cleanup
    cap.release()
    cv2.destroyAllWindows()
    logger.info("üîö Real-time session ended")


def run_batch(processor: PillProcessor, config: dict):
    """‡πÇ‡∏´‡∏°‡∏î Batch: ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå"""
    input_dir = Path(config["INPUT_DIR"])
    if not input_dir.exists():
        logger.error(f"‚ùå Input directory not found: {input_dir}")
        return
        
    # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.webp']
    image_files = []
    for ext in extensions:
        image_files.extend(input_dir.glob(ext))
        
    if not image_files:
        logger.warning(f"‚ö†Ô∏è No images found in {input_dir}")
        return
        
    logger.info(f"üöÄ Batch mode: Processing {len(image_files)} images...")
    
    for idx, img_path in enumerate(image_files, 1):
        logger.info(f"[{idx}/{len(image_files)}] Processing: {img_path.name}")
        
        frame = cv2.imread(str(img_path))
        if frame is None:
            logger.warning(f"‚ö†Ô∏è Could not read: {img_path}")
            continue
            
        pills, _ = processor.process_frame(frame)
        
        if pills:
            logger.info(f"‚úÖ Found {len(pills)} pill(s)")
            for pill in pills:
                processor.save_pill(pill, source_name=img_path.stem)
        else:
            logger.info("‚ÑπÔ∏è  No pills detected")
            
    logger.info(f"‚úÖ Batch complete! Output: {config['OUTPUT_DIR']}")


def main():
    """Entry Point"""
    logger.info("üî∑ Pill Detection System Starting...")
    
    try:
        # Initialize Processor
        processor = PillProcessor(CONFIG)
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        if CONFIG["INPUT_DIR"] is None or CONFIG["INPUT_DIR"] == "":
            logger.info("üìπ Mode: REAL-TIME (Webcam)")
            run_realtime(processor, CONFIG)
        else:
            logger.info(f"üìÅ Mode: BATCH (Folder: {CONFIG['INPUT_DIR']})")
            run_batch(processor, CONFIG)
            
    except KeyboardInterrupt:
        logger.info("‚ö° Interrupted by user")
    except Exception as e:
        logger.error(f"üí• Unexpected error: {e}", exc_info=True)
        sys.exit(1)
    finally:
        cv2.destroyAllWindows()
        logger.info("üîö System shutdown complete")


if __name__ == "__main__":
    main()